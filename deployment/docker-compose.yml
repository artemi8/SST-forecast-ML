services:
  airflow-webserver:
    build:
      context: ./airflow_service
      dockerfile: Dockerfile
    restart: on-failure
    depends_on:
      - airflow-scheduler
      - postgres-db
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://myuser:mypass@postgres-db/airflow_db
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor 
      - AIRFLOW_CONN_SPARK_DEFAULT=spark://spark-master:7077
    ports:
      - "8080:8080"
    command: ["airflow", "webserver"]
    volumes:
      - ./airflow_service/dags:/usr/local/airflow/dags
      - //var/run/docker.sock:/var/run/docker.sock
    networks:
      - airflow-network

  airflow-scheduler:
    build:
      context: ./airflow_service
      dockerfile: Dockerfile
    restart: on-failure
    depends_on:
      - postgres-db
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://myuser:mypass@postgres-db/airflow_db
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW_CONN_SPARK_DEFAULT=spark://spark-master:7077
    command: ["airflow", "scheduler"]
    volumes:
      - ./airflow_service/dags:/usr/local/airflow/dags
      - //var/run/docker.sock:/var/run/docker.sock
    networks:
      - airflow-network

  data-ingestion-service:
    build:
      context: ./data_ingestion_service
      dockerfile: Dockerfile 
    depends_on:
      - cassandra
    networks:
      - airflow-network

  spark-master:
    # image: bitnami-spark-cluster-image:latest 
    build:
      context: ./bitnami_spark_cluster_image
      dockerfile: Dockerfile 
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - JAVA_HOME=/opt/bitnami/java
    networks:
      - airflow-network
    depends_on:
      - cassandra

  spark-worker:
    # image: bitnami-spark-cluster-image:latest
    build:
      context: ./bitnami_spark_cluster_image
      dockerfile: Dockerfile
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
      - JAVA_HOME=/opt/bitnami/java

    depends_on:
      - spark-master
      - cassandra
    networks:
      - airflow-network

  cassandra:
    build:
      context: ./cassandra_service
      dockerfile: Dockerfile 
    ports:
      - "9042:9042"
      - "7199:7199"
    volumes:
      - ./cassandra_service/cassandra-data:/var/lib/cassandra
      - ./cassandra_service/init_db:/docker-entrypoint-initdb.d
    entrypoint: ["/docker-entrypoint-initdb.d/init-cassandra.sh"]
    networks:
      - airflow-network
    environment:
      - CASSANDRA_CLUSTER_NAME=TestCluster


  postgres-db:
    build:
      context: ./postgres_service
      dockerfile: Dockerfile 
    environment:
      POSTGRES_USER: myuser         # Your username
      POSTGRES_PASSWORD: mypass     # Your password
      POSTGRES_DB: airflow_db       # Your database name
    ports:
      - "5432:5432"
    # entrypoint: ["/docker-entrypoint-initdb.d/init-postgres.sh"]
    networks:
      - airflow-network
    volumes:
      - ./postgres_service/postgres-data:/var/lib/postgresql/data  # Persistent data volume
    entrypoint: ["/docker-entrypoint-initdb.d/init-postgres.sh"]
volumes:
  cassandra-data:
  postgres-data:
  init_db:
  dags:

networks:
  airflow-network:
    driver: bridge
